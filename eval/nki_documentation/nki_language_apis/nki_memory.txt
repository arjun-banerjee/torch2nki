-----
nki.language.load

Signature:
nki.language.load(src, *, mask=None, dtype=None, **kwargs)

Description:
Load a tensor from device memory (HBM) into on-chip memory (SBUF).
See Memory hierarchy for detailed information.

Parameters:
src – HBM tensor to load the data from.
mask – (optional) a compile-time constant predicate that controls whether/how this instruction is executed (see NKI API Masking for details)
dtype – (optional) data type to cast the output type to (see Supported Data Types for more information); if not specified, it will default to be the same as the data type of the input tile.

Returns:
a new tile on SBUF with values from src.

Example:
import neuronxcc.nki.language as nl

# load from in_tensor[P, F] that is on HBM
# copy into data_tile[P, F] that is on SBUF
data_tile = nl.load(in_tensor)
...

Note:
Partition dimension size can’t exceed the hardware limitation of nki.language.tile_size.pmax, see Tile size considerations.
Partition dimension has to be the first dimension in the index tuple of a tile. Therefore, data may need to be split into multiple batches to load/store, for example:
import neuronxcc.nki.language as nl

for i_b in nl.affine_range(4):
  data_tile = nl.zeros((128, 512), dtype=in_tensor.dtype) 
  # load from in_tensor[4, 128, 512] one batch at a time
  # copy into data_tile[128, 512]
  i_p, i_f = nl.mgrid[0:128, 0:512]
  data_tile[i_p, i_f] = nl.load(in_tensor[i_b, i_p, i_f])
  ...

Also supports indirect DMA access with dynamic index values:
import neuronxcc.nki.language as nl
...


############################################################################################
# Indirect DMA read example 1:
# - data_tensor on HBM has shape [128 x 512].
# - idx_tensor on HBM has shape [64] (with values [0, 2, 4, 6, ...]).
# - idx_tensor values read from HBM and stored in SBUF idx_tile of shape [64 x 1]
# - data_tensor values read from HBM indexed by values in idx_tile 
#   and store into SBUF data_tile of shape [64 x 512].
############################################################################################
i_p = nl.arange(64)[:, None]
i_f = nl.arange(512)[None, :]

idx_tile = nl.load(idx_tensor[i_p]) # indices have to be in SBUF
data_tile = nl.load(data_tensor[idx_tile[i_p, 0], i_f]) 
...
import neuronxcc.nki.isa as nisa
import neuronxcc.nki.language as nl
...


############################################################################################
# Indirect DMA read example 2:
# - data_tensor on HBM has shape [128 x 512].
# - idx_tile on SBUF has shape [64 x 1] (with values [[0], [2], [4], ...] generated by iota)
# - data_tensor values read from HBM indexed by values in idx_tile 
#   and store into SBUF data_tile of shape [64 x 512].
############################################################################################
i_f = nl.arange(512)[None, :]

idx_expr = 2*nl.arange(64)[:, None]
idx_tile = nisa.iota(idx_expr, dtype=np.int32)
data_tile = nl.load(data_tensor[idx_tile, i_f]) 
...
-----
nki.language.store

Signature:
nki.language.store(dst, value, *, mask=None, **kwargs)

Description:
Store into a tensor on device memory (HBM) from on-chip memory (SBUF).
See Memory hierarchy for detailed information.

Parameters:
dst – HBM tensor to store the data into.
value – An SBUF tile that contains the values to store.
mask – (optional) a compile-time constant predicate that controls whether/how this instruction is executed (see NKI API Masking for details)

Returns:
none

Example:
import neuronxcc.nki.language as nl

...
# store into out_tensor[P, F] that is on HBM
# from data_tile[P, F] that is on SBUF
nl.store(out_tensor, data_tile)

Note:
Partition dimension size can’t exceed the hardware limitation of nki.language.tile_size.pmax, see Tile size considerations.
Partition dimension has to be the first dimension in the index tuple of a tile. Therefore, data may need to be split into multiple batches to load/store, for example:
import neuronxcc.nki.language as nl

for i_b in nl.affine_range(4):
  data_tile = nl.zeros((128, 512), dtype=in_tensor.dtype) 

...
# store into out_tensor[4, 128, 512] one batch at a time
# from data_tile[128, 512] 
i_p, i_f = nl.mgrid[0:128, 0:512]
nl.store(out_tensor[i_b, i_p, i_f], value=data_tile[i_p, i_f]) 

Also supports indirect DMA access with dynamic index values:
import neuronxcc.nki.language as nl
...


##################################################################################
# Indirect DMA write example 1:
#  - data_tensor has shape [128 x 512].
#  - idx_tensor on HBM has shape [64] (with values [0, 2, 4, 6, ...]).
#  - idx_tensor values read from HBM and stored in SBUF idx_tile.
#  - data_tile of shape [64 x 512] values written into
#    HBM data_tensor indexed by values in idx_tile.
##################################################################################
i_p = nl.arange(64)[:, None]
i_f = nl.arange(512)[None, :]
idx_tile = nl.load(idx_tensor[i_p]) # indices have to be in SB

nl.store(data_tensor[idx_tile[i_p, 0], i_f], value=data_tile[0:64, 0:512])
import neuronxcc.nki.isa as nisa
import neuronxcc.nki.language as nl
...


#############################################################################################
# Indirect DMA write example 2:
#  - data_tensor has shape [128 x 512].
#  - idx_tile on SBUF has shape [64 x 1] (with values [[0], [2], [4], ...] generated by iota)
#  - data_tile of shape [64 x 512] values written into
#    HBM data_tensor indexed by values in idx_tile.
#############################################################################################
idx_expr = 2*nl.arange(64)[:, None]
idx_tile = nisa.iota(idx_expr, dtype=np.int32)

nl.store(data_tensor[idx_tile, i_f], value=data_tile[0:64, 0:512]) 
-----
nki.language.load_transpose2d

Signature:
nki.language.load_transpose2d(src, *, mask=None, dtype=None, **kwargs)

Description:
Load a tensor from device memory (HBM) and 2D-transpose the data before storing into on-chip memory (SBUF).

Parameters:
src – HBM tensor to load the data from.
mask – (optional) a compile-time constant predicate that controls whether/how this instruction is executed (see NKI API Masking for details)
dtype – (optional) data type to cast the output type to (see Supported Data Types for more information); if not specified, it will default to be the same as the data type of the input tile.

Returns:
a new tile on SBUF with values from src 2D-transposed.

Example:
import neuronxcc.nki.language as nl
from neuronxcc.nki.typing import tensor
...


# load from in_tensor[F, P] that is on HBM
# transpose and copy into local_tile[P, F] that is on SBUF
N, M = in_tensor.shape
local_tile: tensor[M, N] = nl.load_transpose2d(in_tensor)
...

Note:
Partition dimension size can’t exceed the hardware limitation of nki.language.tile_size.pmax, see Tile size considerations.
-----
nki.language.atomic_rmw

Signature:
nki.language.atomic_rmw(dst, value, op, *, mask=None, **kwargs)

Description:
Perform an atomic read-modify-write operation on HBM data dst = op(dst, value)

Parameters:
dst – HBM tensor with subscripts, only supports indirect dynamic indexing currently.
value – tile or scalar value that is the operand to op.
op – atomic operation to perform, only supports np.add currently.
mask – (optional) a compile-time constant predicate that controls whether/how this instruction is executed (see NKI API Masking for details)

Returns:
none

Example:
import neuronxcc.nki.language as nl
from neuronxcc.nki.typing import tensor
...

value: tensor[N, M] = nl.load(value_tensor)

# dynamic indices have to be in SBUF, with shape [N, 1]
indices_tile: tensor[N, 1] = nl.load(indices_tensor)

ix = nl.arange(M)[None, :]

########################################################################
# Atomic read-modify-write example:
#   - read: values of rmw_tensor is indexed by values from indices_tile
#   - modify: incremented by value
#   - write: saved back into rmw_tensor
# resulting in rmw_tensor = rmw_tensor + value
########################################################################
nl.atomic_rmw(rmw_tensor[indices_tile, ix], value=value, op=np.add)
-----
nki.language.copy

Signature:
nki.language.copy(src, *, mask=None, dtype=None, **kwargs)

Description:
Create a copy of the src tile.

Parameters:
src – the source of copy, must be a tile in SBUF or PSUM.
mask – (optional) a compile-time constant predicate that controls whether/how this instruction is executed (see NKI API Masking for details)
dtype – (optional) data type to cast the output type to (see Supported Data Types for more information); if not specified, it will default to be the same as the data type of the input tile.

Returns:
a new tile with the same layout as src, this new tile will be in SBUF, but can be also assigned to a PSUM tensor.
