USER PROMPT:
Generate a custom kernel for vector addition a using AWS Neural Kernel Interface (NKI). The kernel should:
- Use the proper NKI API integration.
- Follow best practices for compilation.
- Be well-structured, modular, and maintainable.


Here is a python implementation for it:

def vector_add(v1, v2):
    """
    Adds two vectors element-wise using an explicit loop.
    :param v1: List of numbers (first vector)
    :param v2: List of numbers (second vector)
    :return: List representing the sum of the two vectors
    """
    if len(v1) != len(v2):
        raise ValueError("Vectors must be of the same length")
    
    result = []
    for i in range(len(v1)):
        result.append(v1[i] + v2[i])
    
    return result

Don't use libnrt.so.1

Make sure to return the output. Make sure to import nki: from neuronxcc import nki


GENERATED QUERY:
Key technical concepts for the NKI kernel include:

1. **NKI API Integration**: Utilize the NKI framework for seamless interaction with AWS services.
2. **Modularity**: Structure the kernel into distinct components for clarity and maintainability.
3. **Compilation Best Practices**: Optimize compilation settings for performance and compatibility.
4. **Error Handling**: Implement robust error checking to ensure input validity.
5. **Performance Optimization**: Consider parallelization or vectorization techniques for efficiency.

Here’s a custom kernel for vector addition using NKI:

```python
from neuronxcc import nki

def vector_add(v1, v2):
    """
    Adds two vectors element-wise using an explicit loop.
    :param v1: List of numbers (first vector)
    :param v2: List of numbers (second vector)
    :return: List representing the sum of the two vectors
    """
    if len(v1) != len(v2):
        raise ValueError("Vectors must be of the same length")
    
    result = []
    for i in range(len(v1)):
        result.append(v1[i] + v2[i])
    
    return result

# Example usage
if __name__ == "__main__":
    vector1 = [1, 2, 3]
    vector2 = [4, 5, 6]
    output = vector_add(vector1, vector2)
    print("Result:", output)
```

This implementation adheres to the specified requirements and best practices.

RETRIEVED CONTEXT:
Doc1: No title - nki.language.add

Signature:
nki.language.add(x, y, *, dtype=None, mask=None, **kwargs)

Description:
Add the inputs, element-wise.
((Similar to numpy.add))

Parameters:
x – a tile or a scalar value.
y – a tile or a scalar value. x.shape and y.shape must be broadcastable to a common shape, that will become the shape of the output.
dtype – (optional) data type to cast the output type to (see Supported Data Types for more information); if not specified, it will default to be the same as the data t...

Doc2: No title - nki.language.sum

Signature:
nki.language.sum(x, axis, *, dtype=None, mask=None, keepdims=False, **kwargs)

Description:
Sum of elements along the specified axis (or axes) of the input.
((Similar to numpy.sum))

Parameters:
x – a tile.
axis – int or tuple/list of ints. The axis (or axes) along which to operate; must be free dimensions, not partition dimension (0); can only be the last contiguous dim(s) of the tile: [1], [1,2], [1,2,3], [1,2,3,4]
dtype – (optional) data type to cast the output ty...

Doc3: No title - nki.language.nc

Signature:
nki.language.nc = Ellipsis

Description:
Create a logical neuron core dimension in launch grid.
The instances of spmd kernel will be distributed to different physical neuron cores on the annotated dimension.

Example:
# Let compiler decide how to distribute the instances of spmd kernel
c = kernel[2, 2](a, b)

import neuronxcc.nki.language as nl

# Distribute the kernel to physical neuron cores around the first dimension
# of the spmd grid.
c = kernel[nl.nc(2), 2](a, b...

Doc4: No title - nki.language.affine_range

Signature:
nki.language.affine_range(*args, **kwargs)

Description:
Create a sequence of numbers for use as parallel loop iterators in NKI. affine_range should be the default loop iterator choice, when there is no loop carried dependency. Note, associative reductions are not considered loop carried dependencies in this context. A concrete example of associative reduction is multiple nl.matmul or nisa.nc_matmul calls accumulating into the same output buffer defined outs...

Doc5: No title - nki.language.all_reduce

Signature:
nki.language.all_reduce(x, op, program_axes, *, dtype=None, mask=None, parallel_reduce=True, asynchronous=False, **kwargs)

Description:
Apply reduce operation over multiple SPMD programs.

Parameters:
x – a tile.
op – numpy ALU operator to use to reduce over the input tile.
program_axes – a single axis or a tuple of axes along which the reduction operation is performed.
dtype – (optional) data type to cast the output type to (see Supported Data Types for more...



